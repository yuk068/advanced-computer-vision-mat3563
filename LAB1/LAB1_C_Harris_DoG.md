# Lab1 C: Harris Difference of Gaussian

Note: Because the task is pretty much already completed in the reference notebook, for LAB1 C, I will not be providing a notebook, only this report. Reference notebook(s) are in `reference_notebooks/`.

## Introduction

This report details the implementation of a keypoint detection system that combines the Difference of Gaussian (DoG) for scale-invariant feature detection with the Harris Corner Detector for robust corner identification. The system, as implemented in the provided `dog_harris_detections.ipynb` notebook, aims to find scale-invariant keypoints by leveraging the strengths of both algorithms. DoG is primarily used to identify potential interest points across various scales, while the Harris detector refines these candidates by emphasizing strong corners and suppressing edge-like structures. This hybrid approach is commonly employed in computer vision for tasks such as object recognition, image matching, and 3D reconstruction, where reliable and repeatable feature points are crucial.

The `dog_harris_detections.ipynb` notebook provides a practical example of this combined approach, including functionalities for generating Gaussian and DoG pyramids, applying Harris response, performing non-maximum suppression, and filtering out edge responses. It also includes utilities for saving detected keypoints to a CSV file, overlaying them on the original image, and visualizing Harris heatmaps across different scales and octaves. This report will delve into the theoretical underpinnings, mathematical formulations, and practical insights derived from this implementation, supplemented by additional research to provide a comprehensive understanding of the techniques involved.

## Difference of Gaussian (DoG)

### Theory and Concept

The Difference of Gaussian (DoG) is a feature enhancement algorithm used in computer vision, particularly for blob detection and as a fundamental step in scale-invariant feature detection algorithms like SIFT (Scale-Invariant Feature Transform). It approximates the Laplacian of Gaussian (LoG) operator, which is known for its ability to detect blobs that are invariant to scale changes. The core idea behind DoG is to subtract two Gaussian-blurred versions of an image, where the two Gaussian filters have slightly different standard deviations. This subtraction highlights regions of rapid intensity change, effectively acting as a band-pass filter that attenuates low-frequency (smooth) and high-frequency (noise) components, leaving behind the mid-frequency details that correspond to edges and blobs.

### Scale-Space Representation and Octaves

To achieve scale invariance, images are processed within a **scale-space**. A scale-space is a multi-scale representation of an image, where the image is progressively smoothed with Gaussian filters of increasing standard deviation ($\\sigma$). This creates a stack of images, each representing the original image at a different level of detail. Fine details are visible at small $\\sigma$ values, while coarser structures become apparent at larger $\\sigma$ values.

In the context of DoG, the scale-space is often organized into **octaves**. An octave typically represents a doubling of the image scale (halving of the image resolution). Within each octave, several images are generated by convolving the image with Gaussians of increasing $\\sigma$. This creates a 'pyramid' structure, where each level of the pyramid (octave) contains multiple blurred images (scales). The `dog_harris_detections.ipynb` notebook implements this using `build_gaussian_pyramid`:

```python
def build_gaussian_pyramid(gray, num_octaves=NUM_OCTAVES, s=SCALES_PER_OCT, sigma0=SIGMA0):
    base = gray.astype(np.float32) / 255.0
    k = 2 ** (1.0 / s)
    gauss_pyr, sigmas_pyr = [], []
    for o in range(num_octaves):
        octave_imgs, octave_sigmas = [], []
        sigmas = [sigma0 * (k**i) for i in range(s + 3)]
        if o == 0:
            prev = gaussian_blur(base, np.sqrt(max(sigmas[0]**2 - 0.5**2, 1e-6)))
        else:
            prev = cv2.resize(gauss_pyr[o-1][s], (base.shape[1] >> o, base.shape[0] >> o), interpolation=cv2.INTER_NEAREST)
        octave_imgs.append(prev); octave_sigmas.append(sigmas[0])
        for i in range(1, s+3):
            sigma_prev, sigma_curr = sigmas[i-1], sigmas[i]
            sigma_inc = np.sqrt(max(sigma_curr**2 - sigma_prev**2, 1e-6))
            blur = gaussian_blur(octave_imgs[-1], sigma_inc)
            octave_imgs.append(blur); octave_sigmas.append(sigmas[i])
        gauss_pyr.append(octave_imgs); sigmas_pyr.append(octave_sigmas)
    return gauss_pyr, sigmas_pyr
```

Here, `s` represents the number of scales per octave, and `k` is the multiplicative factor for $\\sigma$ between consecutive scales. The `sigma_inc` calculation ensures that the effective $\\sigma$ for each image in the octave corresponds to the desired scale, building upon the previous blur. The `cv2.resize` operation for subsequent octaves effectively downsamples the image, creating a lower-resolution base for the next octave.

### Mathematical Formulation of DoG

The Gaussian function in 2D is given by:

$$ G(x, y, \sigma) = \frac{1}{2\pi\sigma^2} e^{-\frac{x^2 + y^2}{2\sigma^2}} $$

where $\\sigma$ is the standard deviation. A Gaussian-blurred image $L(x, y, \sigma)$ is obtained by convolving the original image $I(x, y)$ with a Gaussian kernel:

$$ L(x, y, \sigma) = I(x, y) * G(x, y, \sigma) $$

The Difference of Gaussian (DoG) image $D(x, y, \sigma, k)$ is then computed by subtracting two Gaussian-blurred images with standard deviations $\\sigma$ and $k\\sigma$:

$$ D(x, y, \sigma, k) = L(x, y, k\sigma) - L(x, y, \sigma) $$

This operation is an efficient approximation of the scale-normalized Laplacian of Gaussian (LoG), which is defined as:

$$ \nabla^2 L = \frac{\partial^2 L}{\partial x^2} + \frac{\partial^2 L}{\partial y^2} $$

It has been shown that the DoG operator closely approximates the LoG operator, especially when $k \approx 1.6$. The extrema (maxima and minima) in the DoG images correspond to potential keypoints. The `build_dog_pyramid` function in the notebook directly implements this subtraction:

```python
def build_dog_pyramid(gauss_pyr):
    dog_pyr = []
    for octave_imgs in gauss_pyr:
        dogs = [octave_imgs[i] - octave_imgs[i-1] for i in range(1, len(octave_imgs))]
        dog_pyr.append(dogs)
    return dog_pyr
```

### Local Extrema Detection

After generating the DoG pyramid, the next step is to identify potential keypoints by finding local extrema (maxima or minima) in the DoG images. A pixel is considered a local extremum if it is greater than or less than all its 26 neighbors in a $3 \times 3 \times 3$ neighborhood (3x3 spatial neighborhood across 3 adjacent scales). This is implemented in the `is_local_extrema` function:

```python
def is_local_extrema(cube):
    c = cube[1,1,1]
    if c > 0:
        return c == cube.max()
    else:
        return c == cube.min()
```

This function checks if the central pixel `c` is either the maximum or minimum value within the 3D cube of neighbors. These local extrema are candidates for keypoints because they represent points where the image intensity changes most significantly across scales, indicating potential blobs or corners. However, these candidates still need further refinement to remove unstable points and edge responses.


## Harris Corner Detection

### Theory and Concept

The Harris Corner Detector is a classic algorithm in computer vision for identifying corners in an image. A corner is generally defined as a point where there is a significant change in image intensity in at least two directions. Unlike edges, which represent intensity changes in only one direction, corners are stable and distinctive features, making them excellent candidates for keypoints in various computer vision tasks. The Harris detector is robust to rotation, illumination changes, and noise.

The fundamental idea behind the Harris detector is to consider a small window around each pixel and analyze the change in intensity when this window is shifted by a small amount in any direction. If the intensity change is large in all directions, then the pixel is likely a corner. If the change is large in only one direction, it's an edge. If the change is small in all directions, it's a flat region.

### Mathematical Formulation

Let $I(x, y)$ be the image intensity at pixel $(x, y)$. When a window $W(x, y)$ (e.g., a Gaussian window) is shifted by $(\Delta x, \Delta y)$, the change in intensity $E(\Delta x, \Delta y)$ can be expressed as:

$$ E(\Delta x, \Delta y) = \sum_{x,y} W(x,y) [I(x+\Delta x, y+\Delta y) - I(x,y)]^2 $$

Using a Taylor expansion for $I(x+\Delta x, y+\Delta y)$, we get:

$$ I(x+\Delta x, y+\Delta y) \approx I(x,y) + I_x \Delta x + I_y \Delta y $$

where $I_x = \frac{\partial I}{\partial x}$ and $I_y = \frac{\partial I}{\partial y}$ are the image gradients in the x and y directions, respectively. Substituting this into the equation for $E(\Delta x, \Delta y)$ and simplifying, we obtain:

$$ E(\Delta x, \Delta y) \approx [\Delta x, \Delta y] M [\Delta x, \Delta y]^T $$

where $M$ is the **structure tensor** or **second moment matrix**, defined as:

$$ M = \sum_{x,y} W(x,y) \begin{bmatrix} I_x^2 & I_x I_y \\ I_x I_y & I_y^2 \end{bmatrix} = \begin{bmatrix} S_{xx} & S_{xy} \\ S_{xy} & S_{yy} \end{bmatrix} $$

Here, $S_{xx} = \sum W I_x^2$, $S_{yy} = \sum W I_y^2$, and $S_{xy} = \sum W I_x I_y$. The gradients $I_x$ and $I_y$ are typically computed using Sobel operators, and the summation is performed over a local window, often weighted by a Gaussian function (as seen in the `gaussian_blur` applied to `Ixx`, `Iyy`, `Ixy` in the notebook).

The `harris_response` function in the provided notebook calculates these components:

```python
def harris_response(img, k=HARRIS_K, win_sigma=1.0):
    Ix = cv2.Sobel(img, cv2.CV_32F, 1, 0, ksize=3, borderType=cv2.BORDER_REPLICATE)
    Iy = cv2.Sob2el(img, cv2.CV_32F, 0, 1, ksize=3, borderType=cv2.BORDER_REPLICATE)
    Ixx, Iyy, Ixy = Ix*Ix, Iy*Iy, Ix*Iy
    Sxx = gaussian_blur(Ixx, win_sigma)
    Syy = gaussian_blur(Iyy, win_sigma)
    Sxy = gaussian_blur(Ixy, win_sigma)
    detM = Sxx*Syy - Sxy*Sxy
    traceM = Sxx + Syy
    R = detM - k*(traceM**2)
    return R
```

### Corner Response Function (CRF)

The properties of $M$ (specifically its eigenvalues $\lambda_1$ and $\lambda_2$) determine whether a region is flat, an edge, or a corner:

*   **Flat region:** Both $\lambda_1$ and $\lambda_2$ are small.
*   **Edge:** One eigenvalue is large (along the edge direction), and the other is small.
*   **Corner:** Both $\lambda_1$ and $\lambda_2$ are large.

Instead of directly computing eigenvalues, Harris and Stephens proposed a **corner response function (CRF)** $R$ that avoids the costly eigenvalue decomposition:

$$ R = \text{det}(M) - k (\text{trace}(M))^2 $$

where $\text{det}(M) = S_{xx}S_{yy} - S_{xy}^2$ and $\text{trace}(M) = S_{xx} + S_{yy}$. The parameter $k$ is an empirical constant, typically in the range $[0.04, 0.06]$. A large positive value of $R$ indicates a corner, a large negative value indicates an edge, and a small absolute value indicates a flat region. The `harris_response` function calculates this $R$ value for each pixel.

### Edge Response Filtering

While the Harris detector is good at identifying corners, it can sometimes produce strong responses along edges. To mitigate this, a common practice is to apply **edge response filtering**. This technique uses the ratio of the eigenvalues of the structure tensor to distinguish between corners and edges. For a perfect edge, one eigenvalue is much larger than the other, resulting in a high ratio. For a corner, both eigenvalues are large and roughly equal, leading to a smaller ratio.

The `pass_edge_response` function in the notebook implements this filtering:

```python
def pass_edge_response(dog, y, x, r=EDGE_R):
    Dxx = dog[y, x+1] + dog[y, x-1] - 2*dog[y, x]
    Dyy = dog[y+1, x] + dog[y-1, x] - 2*dog[y, x]
    Dxy = (dog[y+1, x+1] - dog[y+1, x-1] - dog[y-1, x+1] + dog[y-1, x-1]) * 0.25
    Tr = Dxx + Dyy
    Det = Dxx*Dyy - Dxy*Dxy
    if Det <= 0:
        return False
    ratio = (Tr*Tr) / Det
    rcrit = ((r + 1.0)**2) / r
    return ratio < rcrit
```

This function approximates the second derivatives ($Dxx, Dyy, Dxy$) to form a Hessian-like matrix. The ratio $(Tr^2)/Det$ is then compared against a critical ratio `rcrit` (derived from the user-defined parameter `r`). If this ratio is too high, it indicates an edge-like structure, and the point is rejected.

### Non-Maximum Suppression (NMS)

After computing the Harris response and filtering out edge responses, there might still be multiple adjacent pixels that all have high corner response values, forming a cluster around a true corner. **Non-maximum suppression (NMS)** is used to thin these responses down to a single, most representative keypoint. For each potential keypoint, NMS suppresses all other keypoints within a defined radius that have a lower response score.

The `nonmax_suppression` function in the notebook performs this task:

```python
def nonmax_suppression(points, radius):
    if not points:
        return []
    pts = np.array(points)
    order = np.argsort(-pts[:,2]) # Sort by score in descending order
    kept, taken = [], np.zeros(len(points), dtype=bool)
    for i in order:
        if taken[i]:
            continue
        yi, xi, _ = pts[i]
        kept.append(points[i])
        dy = pts[:,0] - yi
        dx = pts[:,1] - xi
        mask = (dx*dx + dy*dy) <= (radius*radius)
        taken = taken | mask
    return kept
```

The function sorts the candidate points by their Harris response score in descending order. It then iterates through the sorted points. For each point, if it hasn't been 


taken (i.e., suppressed by a stronger point), it is added to the `kept` list, and all other points within its `radius` are marked as `taken` (suppressed). This ensures that only the strongest response within a local neighborhood is retained.

## Combining DoG and Harris for Keypoint Detection

The `detect_keypoints_dog_harris` function orchestrates the entire process, combining the scale-space capabilities of DoG with the robust corner detection of Harris. The synergy between these two algorithms allows for the detection of keypoints that are both scale-invariant and structurally significant (corners).

### Process Flow:

1.  **Gaussian Pyramid Construction:** The `build_gaussian_pyramid` function creates a multi-scale representation of the input grayscale image. This involves generating several blurred images (scales) within each octave, with each subsequent octave being a downsampled version of the previous one. This step is crucial for achieving scale invariance, as it allows features to be detected at different resolutions.

2.  **Difference of Gaussian (DoG) Pyramid Construction:** The `build_dog_pyramid` function then computes the Difference of Gaussian images by subtracting adjacent Gaussian-blurred images within each octave. The extrema in these DoG images are potential keypoint locations, indicating regions of significant intensity change across scales.

3.  **Harris Response Calculation:** For each Gaussian image in the pyramid (excluding the base and top images used for DoG calculation), the `harris_response` function calculates the Harris corner response. This provides a measure of corner-likeness for each pixel at that specific scale.

4.  **Keypoint Candidate Selection:** The algorithm then iterates through the DoG images, searching for local extrema in a $3 \times 3 \times 3$ neighborhood (spatial and scale dimensions). These extrema are filtered based on a `contrast_th` to remove weak responses, ensuring only significant changes are considered.

5.  **Edge Response Filtering:** To eliminate edge-like features that might have strong DoG responses but are not true corners, the `pass_edge_response` function is applied. This uses the ratio of eigenvalues (approximated by the trace and determinant of the structure tensor) to discard points that exhibit strong responses primarily along a single direction.

6.  **Harris Response Thresholding:** Only keypoint candidates with a Harris response `Rh` above a relative threshold `R_thr` (calculated as a percentage of the maximum Harris response in that scale) are retained. This ensures that only strong corners are selected.

7.  **Non-Maximum Suppression (NMS):** Finally, `nonmax_suppression` is applied to the remaining keypoint candidates. This step eliminates redundant keypoints by selecting only the strongest response within a local `nms_radius`, ensuring that each detected corner is represented by a single, optimal point.

8.  **Scale and Coordinate Normalization:** The detected keypoints, which are initially found at specific octave and scale indices, are then normalized back to the original image coordinates and assigned an effective `sigma` value, representing their characteristic scale.

This combined approach effectively leverages the strengths of both DoG for scale-space exploration and Harris for robust corner detection, resulting in a set of stable and distinctive keypoints suitable for various computer vision applications.

## Parameters and Their Significance

The `dog_harris_detections.ipynb` notebook defines several parameters that control the behavior of the keypoint detection process. Understanding their significance is crucial for tuning the algorithm for different image types and application requirements.

*   `SIGMA0` (default: 1.6): The initial scale (standard deviation of the Gaussian filter) for the first image in the first octave. This influences the smallest features that can be detected.
*   `SCALES_PER_OCT` (default: 3): The number of scales (blurred images) generated within each octave. A higher number of scales allows for finer resolution in scale-space, potentially detecting more keypoints but increasing computational cost.
*   `NUM_OCTAVES` (default: 4): The total number of octaves to generate. More octaves allow for the detection of larger features at coarser resolutions. Each octave typically halves the image resolution.
*   `CONTRAST_TH` (default: 0.03): A threshold for the absolute value of the DoG response. Keypoints with a DoG response below this threshold are considered low-contrast and are discarded, helping to remove noise.
*   `EDGE_R` (default: 10): The ratio threshold used in edge response filtering. A higher value makes the filter more lenient, allowing more edge-like features to pass. A lower value makes it stricter, rejecting more edges.
*   `HARRIS_K` (default: 0.04): The empirical constant $k$ in the Harris corner response function. This value typically ranges from 0.04 to 0.06. It balances the contribution of the determinant and trace of the structure tensor.
*   `HARRIS_REL_TH` (default: 0.01): A relative threshold for the Harris corner response. Keypoints are only accepted if their Harris response is above this fraction of the maximum Harris response in that scale. This helps in selecting only the strongest corners.
*   `NMS_RADIUS` (default: 3): The radius for non-maximum suppression. Keypoints within this radius of a stronger keypoint are suppressed. A larger radius leads to fewer, more spread-out keypoints.
*   `DRAW_SIZE` (default: 3): The size of the circle used to draw keypoints on the overlay image.

## Insights and Comparisons

### DoG vs. LoG

The Difference of Gaussian (DoG) is widely used as an efficient approximation of the Laplacian of Gaussian (LoG). While LoG provides a theoretically sound basis for blob detection and scale-space extrema, its direct computation involves convolving with a second-order derivative filter, which can be computationally more expensive. DoG, by simply subtracting two Gaussian-blurred images, offers a computationally cheaper alternative that yields very similar results, especially when the ratio of the standard deviations of the two Gaussians is approximately 1.6. This approximation is a cornerstone of efficient scale-invariant feature detection algorithms.

### Harris Corner Detector Strengths and Weaknesses

**Strengths:**
*   **Rotation Invariance:** The Harris corner response function is invariant to image rotation because it is based on the eigenvalues of the structure tensor, which are rotation-invariant properties.
*   **Partial Illumination Invariance:** It is relatively robust to changes in illumination, as it relies on intensity gradients rather than absolute intensity values.
*   **Computational Efficiency:** Compared to some other feature detectors, the Harris detector is relatively fast to compute.
*   **Well-defined Mathematical Basis:** Its foundation in the structure tensor and eigenvalue analysis provides a clear understanding of what constitutes a corner.

**Weaknesses:**
*   **Not Scale Invariant:** The original Harris detector is not inherently scale-invariant. A corner detected at one scale might not be detected at another. This limitation is precisely why it is combined with scale-space techniques like DoG in this implementation.
*   **Sensitivity to Noise:** Like many gradient-based methods, it can be sensitive to noise, which can lead to spurious corner detections. Gaussian smoothing (as part of the DoG process and within the Harris response calculation) helps to mitigate this.
*   **Threshold Dependency:** The performance heavily relies on the chosen threshold for the corner response function, which often requires manual tuning.

### The Hybrid DoG + Harris Approach

The combination of DoG and Harris addresses the primary weakness of the standalone Harris detector: its lack of scale invariance. By performing Harris corner detection within the scale-space generated by DoG, the system can identify corners that are stable across different scales. The DoG pyramid effectively localizes potential interest points in both spatial and scale dimensions, while the Harris response then acts as a robust filter to select only the corner-like features among these candidates. This hybrid approach yields keypoints that are not only distinctive but also robust to changes in scale, rotation, and moderate illumination variations, making them highly valuable for various computer vision applications.

## Conclusion

The `dog_harris_detections.ipynb` notebook provides a robust implementation of a keypoint detection system that effectively combines the Difference of Gaussian (DoG) for scale-space analysis with the Harris Corner Detector for precise corner localization. This synergistic approach allows for the identification of keypoints that are invariant to scale and rotation, making them highly suitable for tasks requiring reliable feature matching and object recognition. The detailed breakdown of Gaussian pyramid construction, DoG computation, Harris response calculation, edge filtering, and non-maximum suppression highlights the intricate steps involved in building such a system. Understanding the theoretical underpinnings and the role of each parameter is essential for optimizing performance and adapting the algorithm to diverse image processing challenges.

## References

1.  [Difference of Gaussians - Wikipedia](https://en.wikipedia.org/wiki/Difference_of_Gaussians)
2.  [Harris corner detector - Wikipedia](https://en.wikipedia.org/wiki/Harris_corner_detector)
3.  [Introduction to Harris Corner Detector | by Deep](https://medium.com/@deepanshut041/introduction-to-harris-corner-detector-32a88850b3f6)
4.  [Scale space - Wikipedia](https://en.wikipedia.org/wiki/Scale_space)
5.  [Non Maximum Suppression: Theory and Implementation in PyTorch](https://learnopencv.com/non-maximum-suppression-theory-and-implementation-in-pytorch/)


