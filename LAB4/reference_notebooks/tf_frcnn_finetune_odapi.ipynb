{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e9c1dc5",
   "metadata": {},
   "source": [
    "# Faster R-CNN (TensorFlow Object Detection API) — End-to-End Fine-tuning Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c41731d",
   "metadata": {},
   "source": [
    "Tệp nguồn này thiết lập một pipeline fine-tuning có thể tái lập cho Faster R-CNN + ResNet50 + FPN sử dụng TensorFlow Object Detection API (TF2). Chạy các cell theo thứ tự trên xuống\n",
    "\n",
    "**Những việc sẽ làm trong chương trình**:\n",
    "\n",
    "- Cài đặt môi trường và TensorFlow Object Detection API\n",
    "- Tải một tập dữ liệu nhỏ (**PennFudanPed**) và chuyển đổi sang định dạng TFRecord, đây sẽ được dùng làm tập huấn luyện\n",
    "- Tạo tệp **label_map.pbtxt** là tệp chứa nhãn các đối tượng trong tập dữ liệu huấn luyện mới\n",
    "- Tải **checkpoint** đã huấn luyện sẵn (**Faster R-CNN ResNet50 V1 FPN**) từ **TF2 Model Zoo**\n",
    "- Tự động tạo **file pipeline.config** tương thích\n",
    "- Huấn luyện mô hình bằng **model_main_tf2.py**\n",
    "- Xuất **SavedModel** bằng exporter_main_v2.py\n",
    "- Chạy **inference** và trực quan hóa kết quả detection\n",
    "\n",
    "\n",
    "> ⚠️ Recommended: Run on GPU (Colab or local with CUDA). Tested with **TF 2.13–2.15**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed71b73a",
   "metadata": {},
   "source": [
    "## 1) Runtime check & project paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3000c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os, sys\n",
    "\n",
    "PROJECT_ROOT = os.path.abspath(\".\")\n",
    "WORK_DIR = os.path.join(PROJECT_ROOT, \"tf_frcnn_work\")\n",
    "DATA_DIR = os.path.join(WORK_DIR, \"data\")\n",
    "MODEL_DIR = os.path.join(WORK_DIR, \"model_dir\")\n",
    "EXPORT_DIR = os.path.join(WORK_DIR, \"exported\")\n",
    "PIPELINE_DIR = os.path.join(WORK_DIR, \"pipeline\")\n",
    "CKPT_DIR = os.path.join(WORK_DIR, \"pretrained_ckpt\")\n",
    "OD_API_DIR = os.path.join(WORK_DIR, \"models\")  # if we clone the TF models repo\n",
    "\n",
    "for d in [WORK_DIR, DATA_DIR, MODEL_DIR, EXPORT_DIR, PIPELINE_DIR, CKPT_DIR]:\n",
    "    os.makedirs(d, exist_ok=True)\n",
    "\n",
    "print(\"PROJECT_ROOT:\", PROJECT_ROOT)\n",
    "print(\"WORK_DIR:\", WORK_DIR)\n",
    "print(\"Using Python:\", sys.version)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "517591d4",
   "metadata": {},
   "source": [
    "## 2) Install TensorFlow & Object Detection API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ffd7c4",
   "metadata": {},
   "source": [
    "We try two approaches:\n",
    "\n",
    "- **Preferred (simple)**: pip install OD API subpackage.\n",
    "- **Fallback**: clone repo & compile protos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db30c967",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import sys, subprocess, os, shutil\n",
    "\n",
    "def run(cmd):\n",
    "    print(\">>>\", cmd)\n",
    "    r = subprocess.run(cmd, shell=True, check=False)\n",
    "    print(\"Return code:\", r.returncode)\n",
    "    return r.returncode == 0\n",
    "\n",
    "ok = run(\"pip install --upgrade pip\")\n",
    "ok = run(\"pip install 'tensorflow>=2.13,<2.16'\")\n",
    "ok = run(\"pip install Cython contextlib2 pillow lxml jupyter matplotlib pandas tf-models-official==2.15.0 --no-deps\")\n",
    "ok = run(\"pip install protobuf==4.25.3\")\n",
    "ok = run(\"pip install --no-cache-dir 'git+https://github.com/tensorflow/models.git#egg=object-detection&subdirectory=research/object_detection'\")\n",
    "\n",
    "if not ok:\n",
    "    print(\"\\nDirect pip install failed. Cloning repo & building protos as fallback...\")\n",
    "    os.makedirs(OD_API_DIR, exist_ok=True)\n",
    "    os.chdir(WORK_DIR)\n",
    "    run(\"git clone --depth 1 https://github.com/tensorflow/models.git\")\n",
    "    os.chdir(os.path.join(WORK_DIR, \"models\", \"research\"))\n",
    "    run(\"apt-get update && apt-get install -y protobuf-compiler\")  # may fail on non-Debian systems; ignore errors\n",
    "    run(\"protoc object_detection/protos/*.proto --python_out=.\")\n",
    "    run(\"pip install .\")\n",
    "    os.chdir(PROJECT_ROOT)\n",
    "\n",
    "# Simple import test\n",
    "test_code = \"import object_detection\\nprint('Object Detection API import: OK')\\n\"\n",
    "with open(os.path.join(WORK_DIR, \"od_import_test.py\"), \"w\") as f:\n",
    "    f.write(test_code)\n",
    "run(f\"{sys.executable} {os.path.join(WORK_DIR, 'od_import_test.py')}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab74b51d",
   "metadata": {},
   "source": [
    "## 3) Download dataset (PennFudanPed) & convert to TFRecord\n",
    "#####\n",
    "- Mục đích: Chuẩn bị dữ liệu đầu vào cho mô hình.\n",
    "- Giải thích: TF Object Detection API sử dụng định dạng TFRecord — một định dạng nhị phân tối ưu để TensorFlow đọc nhanh trong quá trình huấn luyện. Bộ dữ liệu ví dụ PennFudanPed chứa ảnh người đi bộ và annotation bounding boxes.\n",
    "    - Tải dataset gốc (thường ở dạng ảnh + file annotation VOC hoặc JSON).\n",
    "    - Dùng script chuyển đổi annotation sang định dạng TFRecord kèm thông tin nhãn, tọa độ bounding box."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed4720bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os, zipfile, random, shutil, urllib.request, pathlib, glob, json\n",
    "from PIL import Image\n",
    "random.seed(1337)\n",
    "\n",
    "raw_dir = os.path.join(DATA_DIR, \"raw\")\n",
    "img_dir = os.path.join(DATA_DIR, \"images\")\n",
    "tfrecord_dir = os.path.join(DATA_DIR, \"tfrecord\")\n",
    "os.makedirs(raw_dir, exist_ok=True)\n",
    "os.makedirs(img_dir, exist_ok=True)\n",
    "os.makedirs(tfrecord_dir, exist_ok=True)\n",
    "\n",
    "# Download\n",
    "url = \"https://www.cis.upenn.edu/~jshi/ped_html/PennFudanPed.zip\"\n",
    "zip_path = os.path.join(raw_dir, \"PennFudanPed.zip\")\n",
    "if not os.path.exists(zip_path):\n",
    "    print(\"Downloading:\", url)\n",
    "    urllib.request.urlretrieve(url, zip_path)\n",
    "else:\n",
    "    print(\"Already downloaded:\", zip_path)\n",
    "\n",
    "# Extract\n",
    "extract_root = os.path.join(raw_dir, \"PennFudanPed\")\n",
    "if not os.path.exists(extract_root):\n",
    "    print(\"Extracting...\")\n",
    "    with zipfile.ZipFile(zip_path, 'r') as zf:\n",
    "        zf.extractall(raw_dir)\n",
    "else:\n",
    "    print(\"Already extracted:\", extract_root)\n",
    "\n",
    "png_dir = os.path.join(extract_root, \"PNGImages\")\n",
    "mask_dir = os.path.join(extract_root, \"PedMasks\")\n",
    "\n",
    "def masks_to_boxes(mask_img):\n",
    "    import numpy as np\n",
    "    arr = np.array(mask_img)\n",
    "    inst_ids = np.unique(arr[:,:,0])\n",
    "    inst_ids = [i for i in inst_ids if i != 0]\n",
    "    boxes = []\n",
    "    for iid in inst_ids:\n",
    "        ys, xs = (arr[:,:,0] == iid).nonzero()\n",
    "        if len(xs)==0 or len(ys)==0:\n",
    "            continue\n",
    "        x1, y1, x2, y2 = xs.min(), ys.min(), xs.max(), ys.max()\n",
    "        boxes.append((x1,y1,x2,y2))\n",
    "    return boxes\n",
    "\n",
    "meta = []\n",
    "imgs = sorted(glob.glob(os.path.join(png_dir, '*.png')))\n",
    "for p in imgs:\n",
    "    name = os.path.splitext(os.path.basename(p))[0]\n",
    "    mask_path = os.path.join(mask_dir, name + \"_mask.png\")\n",
    "    if not os.path.exists(mask_path): \n",
    "        continue\n",
    "    im = Image.open(p).convert(\"RGB\")\n",
    "    w,h = im.size\n",
    "    jpg_path = os.path.join(img_dir, name + \".jpg\")\n",
    "    if not os.path.exists(jpg_path):\n",
    "        im.save(jpg_path, quality=95)\n",
    "    mask = Image.open(mask_path).convert(\"RGB\")\n",
    "    boxes = masks_to_boxes(mask)\n",
    "    anns = [{\"category\":\"person\",\"bbox\":[int(x1),int(y1),int(x2),int(y2)]} for (x1,y1,x2,y2) in boxes]\n",
    "    meta.append({\"file_name\": os.path.basename(jpg_path), \"width\": w, \"height\": h, \"annotations\": anns})\n",
    "\n",
    "with open(os.path.join(DATA_DIR, \"pennfudan_meta.json\"), \"w\") as f:\n",
    "    json.dump(meta, f, indent=2)\n",
    "\n",
    "random.shuffle(meta)\n",
    "split = int(0.8*len(meta))\n",
    "train_meta = meta[:split]\n",
    "val_meta = meta[split:]\n",
    "with open(os.path.join(DATA_DIR, \"train.json\"), \"w\") as f:\n",
    "    json.dump(train_meta, f, indent=2)\n",
    "with open(os.path.join(DATA_DIR, \"val.json\"), \"w\") as f:\n",
    "    json.dump(val_meta, f, indent=2)\n",
    "\n",
    "print(\"Train:\", len(train_meta), \"Val:\", len(val_meta))\n",
    "\n",
    "# label_map\n",
    "label_map_path = os.path.join(DATA_DIR, \"label_map.pbtxt\")\n",
    "with open(label_map_path, \"w\") as f:\n",
    "    f.write('item { id: 1 name: \"person\" }\\n')\n",
    "print(\"Wrote\", label_map_path)\n",
    "\n",
    "# TFRecord writer\n",
    "import tensorflow as tf\n",
    "\n",
    "def create_tf_example(rec, label_map):\n",
    "    filename = rec[\"file_name\"].encode(\"utf8\")\n",
    "    width = rec[\"width\"]; height = rec[\"height\"]\n",
    "    xmins, xmaxs, ymins, ymaxs, classes_text, classes = [], [], [], [], [], []\n",
    "    for a in rec[\"annotations\"]:\n",
    "        x1,y1,x2,y2 = a[\"bbox\"]\n",
    "        xmins.append(x1/width); xmaxs.append(x2/width)\n",
    "        ymins.append(y1/height); ymaxs.append(y2/height)\n",
    "        classes_text.append(a[\"category\"].encode(\"utf8\"))\n",
    "        classes.append(label_map[a[\"category\"]])\n",
    "    with tf.io.gfile.GFile(os.path.join(img_dir, rec[\"file_name\"]), \"rb\") as fid:\n",
    "        encoded_jpg = fid.read()\n",
    "\n",
    "    def bytes_feature(v): return tf.train.Feature(bytes_list=tf.train.BytesList(value=[v]))\n",
    "    def float_list_feature(v): return tf.train.Feature(float_list=tf.train.FloatList(value=v))\n",
    "    def int64_list_feature(v): return tf.train.Feature(int64_list=tf.train.Int64List(value=v))\n",
    "\n",
    "    example = tf.train.Example(features=tf.train.Features(feature={\n",
    "        \"image/height\": tf.train.Feature(int64_list=tf.train.Int64List(value=[height])),\n",
    "        \"image/width\": tf.train.Feature(int64_list=tf.train.Int64List(value=[width])),\n",
    "        \"image/filename\": bytes_feature(filename),\n",
    "        \"image/source_id\": bytes_feature(filename),\n",
    "        \"image/encoded\": bytes_feature(encoded_jpg),\n",
    "        \"image/format\": bytes_feature(b\"jpg\"),\n",
    "        \"image/object/bbox/xmin\": float_list_feature(xmins),\n",
    "        \"image/object/bbox/xmax\": float_list_feature(xmaxs),\n",
    "        \"image/object/bbox/ymin\": float_list_feature(ymins),\n",
    "        \"image/object/bbox/ymax\": float_list_feature(ymaxs),\n",
    "        \"image/object/class/text\": tf.train.Feature(bytes_list=tf.train.BytesList(value=classes_text)),\n",
    "        \"image/object/class/label\": int64_list_feature(classes),\n",
    "    }))\n",
    "    return example\n",
    "\n",
    "label_map = {\"person\":1}\n",
    "def write_tfrecord(meta_list, out_path):\n",
    "    with tf.io.TFRecordWriter(out_path) as w:\n",
    "        for r in meta_list:\n",
    "            w.write(create_tf_example(r, label_map).SerializeToString())\n",
    "\n",
    "train_record = os.path.join(tfrecord_dir, \"train.record\")\n",
    "val_record   = os.path.join(tfrecord_dir, \"val.record\")\n",
    "write_tfrecord(train_meta, train_record)\n",
    "write_tfrecord(val_meta, val_record)\n",
    "print(\"Wrote TFRecords:\", train_record, val_record)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d1f32ba",
   "metadata": {},
   "source": [
    "## 4) Download pretrained Faster R-CNN checkpoint (TF2 Model Zoo)\n",
    "##### \n",
    "- Mục đích: Tận dụng mô hình đã được pretrain để rút ngắn thời gian huấn luyện và tăng độ chính xác.\n",
    "- Giải thích: TF2 Model Zoo cung cấp checkpoint pretrained trên COCO hoặc ImageNet. Chọn mô hình Faster R-CNN ResNet50 V1 FPN để fine-tune trên dataset mới. Điều này giúp mô hình bắt đầu từ trọng số đã học được đặc trưng chung, chỉ tinh chỉnh thêm cho dataset của bạn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e864346f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os, urllib.request, tarfile\n",
    "\n",
    "MODEL_ZOO_URL = \"http://download.tensorflow.org/models/object_detection/tf2/20200711/faster_rcnn_resnet50_v1_640x640_coco17_tpu-8.tar.gz\"\n",
    "tar_path = os.path.join(CKPT_DIR, os.path.basename(MODEL_ZOO_URL))\n",
    "\n",
    "if not os.path.exists(tar_path):\n",
    "    print(\"Downloading:\", MODEL_ZOO_URL)\n",
    "    urllib.request.urlretrieve(MODEL_ZOO_URL, tar_path)\n",
    "else:\n",
    "    print(\"Already downloaded:\", tar_path)\n",
    "\n",
    "extract_path = os.path.join(CKPT_DIR, \"faster_rcnn_resnet50_v1_640x640_coco17_tpu-8\")\n",
    "if not os.path.exists(extract_path):\n",
    "    print(\"Extracting...\")\n",
    "    with tarfile.open(tar_path, \"r:gz\") as tfp:\n",
    "        tfp.extractall(CKPT_DIR)\n",
    "else:\n",
    "    print(\"Already extracted:\", extract_path)\n",
    "\n",
    "print(\"Checkpoint dir:\", extract_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a64e182e",
   "metadata": {},
   "source": [
    "## 5) Generate `pipeline.config`\n",
    "#####\n",
    "- Mục đích: Tạo file cấu hình cho quá trình huấn luyện.\n",
    "- Giải thích: pipeline.config chứa tất cả thông số:\n",
    "    - Model config (loại backbone, FPN, số class)\n",
    "    - Train config (batch size, learning rate, optimizer, số step)\n",
    "    - Train input config (đường dẫn TFRecord train, augmentation)\n",
    "    - Eval input config (đường dẫn TFRecord eval) \n",
    "      API hỗ trợ script để sinh tự động dựa trên checkpoint đã tải."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c882ff0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "\n",
    "NUM_CLASSES = 1\n",
    "NUM_STEPS = 3000\n",
    "\n",
    "label_map = os.path.join(DATA_DIR, \"label_map.pbtxt\")\n",
    "train_record = os.path.join(DATA_DIR, \"tfrecord\", \"train.record\")\n",
    "val_record   = os.path.join(DATA_DIR, \"tfrecord\", \"val.record\")\n",
    "ckpt_base = os.path.join(CKPT_DIR, \"faster_rcnn_resnet50_v1_640x640_coco17_tpu-8\")\n",
    "ckpt_path = os.path.join(ckpt_base, \"checkpoint\", \"ckpt-0\")\n",
    "\n",
    "pipeline_template = r\"\"\"# Auto-generated pipeline.config for Faster R-CNN ResNet50 V1 FPN (TF2)\n",
    "model {\n",
    "  faster_rcnn {\n",
    "    num_classes: __NUM_CLASSES__\n",
    "    image_resizer { keep_aspect_ratio_resizer { min_dimension: 640 max_dimension: 640 } }\n",
    "    feature_extractor { type: \"faster_rcnn_resnet50_keras\" }\n",
    "    first_stage_anchor_generator {\n",
    "      grid_anchor_generator { scales: [0.25, 0.5, 1.0, 2.0] aspect_ratios: [0.5, 1.0, 2.0] }\n",
    "    }\n",
    "    first_stage_box_predictor_conv_hyperparams {\n",
    "      op: CONV\n",
    "      regularizer { l2_regularizer { weight: 0.0004 } }\n",
    "      initializer { truncated_normal_initializer { stddev: 0.01 } }\n",
    "      activation: RELU_6\n",
    "    }\n",
    "    first_stage_nms_iou_threshold: 0.7\n",
    "    first_stage_nms_score_threshold: 0.0\n",
    "    first_stage_max_proposals: 300\n",
    "    first_stage_localization_loss_weight: 2.0\n",
    "    first_stage_objectness_loss_weight: 1.0\n",
    "    initial_crop_size: 14\n",
    "    maxpool_kernel_size: 2\n",
    "    maxpool_stride: 2\n",
    "    second_stage_box_predictor { mask_rcnn_box_predictor { fc_hyperparams { op: FC regularizer { l2_regularizer { weight: 0.0004 } } initializer { variance_scaling_initializer {} } activation: RELU } } }\n",
    "    second_stage_post_processing {\n",
    "      batch_non_max_suppression {\n",
    "        score_threshold: 0.05\n",
    "        iou_threshold: 0.5\n",
    "        max_detections_per_class: 100\n",
    "        max_total_detections: 100\n",
    "      }\n",
    "      score_converter: SIGMOID\n",
    "    }\n",
    "    second_stage_localization_loss_weight: 2.0\n",
    "    second_stage_classification_loss_weight: 1.0\n",
    "  }\n",
    "}\n",
    "\n",
    "train_config {\n",
    "  batch_size: 2\n",
    "  num_steps: __NUM_STEPS__\n",
    "  optimizer {\n",
    "    momentum_optimizer {\n",
    "      learning_rate { cosine_decay_learning_rate { learning_rate_base: 0.02 total_steps: __NUM_STEPS__ warmup_learning_rate: 0.006 warmup_steps: 500 } }\n",
    "      momentum: 0.9\n",
    "    }\n",
    "    use_moving_average: false\n",
    "  }\n",
    "  fine_tune_checkpoint: \"__FINE_TUNE_CKPT__\"\n",
    "  fine_tune_checkpoint_type: \"detection\"\n",
    "  data_augmentation_options { random_horizontal_flip {} }\n",
    "  data_augmentation_options { random_adjust_brightness {} }\n",
    "}\n",
    "\n",
    "train_input_reader {\n",
    "  label_map_path: \"__LABEL_MAP__\"\n",
    "  tf_record_input_reader { input_path: \"__TRAIN_RECORD__\" }\n",
    "}\n",
    "\n",
    "eval_config {\n",
    "  metrics_set: \"coco_detection_metrics\"\n",
    "  use_moving_averages: false\n",
    "  max_evals: 1\n",
    "}\n",
    "\n",
    "eval_input_reader {\n",
    "  label_map_path: \"__LABEL_MAP__\"\n",
    "  shuffle: false\n",
    "  num_readers: 1\n",
    "  tf_record_input_reader { input_path: \"__VAL_RECORD__\" }\n",
    "}\"\"\"\n",
    "\n",
    "pipeline_text = (pipeline_template\n",
    "    .replace(\"__NUM_CLASSES__\", str(NUM_CLASSES))\n",
    "    .replace(\"__NUM_STEPS__\", str(NUM_STEPS))\n",
    "    .replace(\"__FINE_TUNE_CKPT__\", ckpt_path.replace(\"\\\\\",\"/\"))\n",
    "    .replace(\"__LABEL_MAP__\", label_map.replace(\"\\\\\",\"/\"))\n",
    "    .replace(\"__TRAIN_RECORD__\", train_record.replace(\"\\\\\",\"/\"))\n",
    "    .replace(\"__VAL_RECORD__\", val_record.replace(\"\\\\\",\"/\"))\n",
    ")\n",
    "\n",
    "os.makedirs(PIPELINE_DIR, exist_ok=True)\n",
    "pipeline_path = os.path.join(PIPELINE_DIR, \"pipeline.config\")\n",
    "with open(pipeline_path, \"w\") as f:\n",
    "    f.write(pipeline_text)\n",
    "\n",
    "print(\"Wrote pipeline:\", pipeline_path)\n",
    "print(\"Fine-tune checkpoint:\", ckpt_path)\n",
    "print(\"Train record:\", train_record)\n",
    "print(\"Val record:\", val_record)\n",
    "print(\"Label map:\", label_map)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f37221d9",
   "metadata": {},
   "source": [
    "## 6) Train (model_main_tf2.py): \n",
    "##### File nguồn này đã có sẵn khi tải git https://github.com/tensorflow/models/blob/master/research/object_detection/model_main_tf2.py\n",
    "- Mục đích: Huấn luyện mô hình trên dữ liệu của bạn.\n",
    "- Giải thích: Script model_main_tf2.py sẽ:\n",
    "    - Đọc pipeline.config\n",
    "    - Nạp pretrained checkpoint\n",
    "    - Chạy huấn luyện (training loop) và validation theo từng step\n",
    "    - Lưu checkpoint mới theo chu kỳ để có thể resume hoặc xuất mô hình."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34fa0974",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import sys, os, subprocess, shutil\n",
    "\n",
    "def which(script):\n",
    "    return shutil.which(script)\n",
    "\n",
    "entry_model_main = which(\"model_main_tf2.py\")\n",
    "entry_exporter   = which(\"exporter_main_v2.py\")\n",
    "if entry_model_main is None or entry_exporter is None:\n",
    "    guess = os.path.join(WORK_DIR, \"models\", \"research\", \"object_detection\")\n",
    "    alt_model_main = os.path.join(guess, \"model_main_tf2.py\")\n",
    "    alt_exporter   = os.path.join(guess, \"exporter_main_v2.py\")\n",
    "    if os.path.exists(alt_model_main): entry_model_main = alt_model_main\n",
    "    if os.path.exists(alt_exporter):   entry_exporter   = alt_exporter\n",
    "\n",
    "print(\"model_main_tf2.py path:\", entry_model_main)\n",
    "print(\"exporter_main_v2.py path:\", entry_exporter)\n",
    "\n",
    "assert entry_model_main and os.path.exists(entry_model_main), \"Cannot find model_main_tf2.py\"\n",
    "assert entry_exporter and os.path.exists(entry_exporter), \"Cannot find exporter_main_v2.py\"\n",
    "\n",
    "os.makedirs(MODEL_DIR, exist_ok=True)\n",
    "\n",
    "cmd = f'\"{sys.executable}\" \"{entry_model_main}\" --model_dir=\"{MODEL_DIR}\" --pipeline_config_path=\"{os.path.join(PIPELINE_DIR, \"pipeline.config\")}\" --num_train_steps=3000 --sample_1_of_n_eval_examples=1'\n",
    "print(\"Run this to start training:\")\n",
    "print(cmd)\n",
    "# Uncomment the line below to actually run training inside the notebook cell\n",
    "# subprocess.run(cmd, shell=True, check=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0445b14e",
   "metadata": {},
   "source": [
    "## 7) Export SavedModel (exporter_main_v2.py)\n",
    "##### Tương tự, file nguồn này đã có sẵn khi tải git https://github.com/tensorflow/models/blob/master/research/object_detection/exporter_main_v2.py\n",
    "- Mục đích: Xuất mô hình đã huấn luyện ra định dạng SavedModel để triển khai hoặc inference.\n",
    "- Giải thích: exporter_main_v2.py lấy checkpoint cuối, gói toàn bộ graph + trọng số thành một thư mục SavedModel mà TensorFlow Serving, TFLite hay TF Hub có thể dùng."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b04521a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os, sys, glob, subprocess\n",
    "\n",
    "entry_exporter = shutil.which(\"exporter_main_v2.py\")\n",
    "if entry_exporter is None:\n",
    "    guess = os.path.join(WORK_DIR, \"models\", \"research\", \"object_detection\", \"exporter_main_v2.py\")\n",
    "    if os.path.exists(guess):\n",
    "        entry_exporter = guess\n",
    "\n",
    "if not os.path.exists(MODEL_DIR):\n",
    "    raise SystemExit(\"MODEL_DIR not found. Train first.\")\n",
    "\n",
    "cmd = f'\"{sys.executable}\" \"{entry_exporter}\" --input_type=image_tensor --pipeline_config_path=\"{os.path.join(PIPELINE_DIR, \"pipeline.config\")}\" --trained_checkpoint_dir=\"{MODEL_DIR}\" --output_directory=\"{EXPORT_DIR}\"'\n",
    "print(\"Run this to export SavedModel:\")\n",
    "print(cmd)\n",
    "# Uncomment to execute:\n",
    "# subprocess.run(cmd, shell=True, check=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e23bae",
   "metadata": {},
   "source": [
    "## 8) Inference & visualization on a few validation images\n",
    "#####\n",
    "- Mục đích: Kiểm tra kết quả, chạy thử mô hình đã fine-tune và xem bounding boxes trực quan.\n",
    "- Giải thích: Dùng SavedModel đã xuất để dự đoán trên ảnh mới. Sau đó, dùng OpenCV hoặc Matplotlib vẽ khung (rectangle) và nhãn class (putText) lên ảnh để kiểm tra chất lượng mô hình."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f552a251",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os, glob, json\n",
    "import numpy as np\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import tensorflow as tf\n",
    "\n",
    "# locate any saved_model under EXPORT_DIR\n",
    "saved_model_dir = None\n",
    "for p in glob.glob(os.path.join(EXPORT_DIR, \"*\")):\n",
    "    sm = os.path.join(p, \"saved_model\")\n",
    "    if os.path.isdir(sm):\n",
    "        saved_model_dir = sm; break\n",
    "\n",
    "if not saved_model_dir:\n",
    "    print(\"No exported SavedModel found. Export first.\")\n",
    "else:\n",
    "    print(\"Loading:\", saved_model_dir)\n",
    "    detect_fn = tf.saved_model.load(saved_model_dir)\n",
    "\n",
    "    with open(os.path.join(DATA_DIR, \"val.json\")) as f:\n",
    "        val_meta = json.load(f)\n",
    "\n",
    "    os.makedirs(\"viz_results\", exist_ok=True)\n",
    "    for rec in val_meta[:10]:\n",
    "        ip = os.path.join(DATA_DIR, \"images\", rec[\"file_name\"])\n",
    "        img = Image.open(ip).convert(\"RGB\")\n",
    "        np_img = np.array(img)\n",
    "        out = detect_fn(tf.convert_to_tensor(np_img)[None, ...])\n",
    "\n",
    "        boxes = out[\"detection_boxes\"][0].numpy()\n",
    "        scores = out[\"detection_scores\"][0].numpy()\n",
    "        classes = out[\"detection_classes\"][0].numpy().astype(int)\n",
    "\n",
    "        H,W = np_img.shape[:2]\n",
    "        draw = img.copy(); D = ImageDraw.Draw(draw)\n",
    "        for b,s,c in zip(boxes, scores, classes):\n",
    "            if s < 0.5: continue\n",
    "            y1,x1,y2,x2 = b\n",
    "            x1,y1,x2,y2 = x1*W, y1*H, x2*W, y2*H\n",
    "            D.rectangle([x1,y1,x2,y2], outline=(255,0,0), width=3)\n",
    "            D.text((x1,y1), f\"person:{s:.2f}\", fill=(255,0,0))\n",
    "        out_path = os.path.join(\"viz_results\", f\"viz_{rec['file_name']}\")\n",
    "        draw.save(out_path)\n",
    "        print(\"Saved:\", out_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c9efb1e",
   "metadata": {},
   "source": [
    "## 9) Tips & Troubleshooting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57db734c",
   "metadata": {},
   "source": [
    "- Nếu `protoc` bị thiếu, hãy cài đặt nó (Colab: `apt-get install -y protobuf-compiler`, Windows: tải xuống protoc và thêm vào PATH).\n",
    "- Ghim các phiên bản tương thích nếu bạn thấy vấn đề phụ thuộc: `pip install \"tensorflow>=2.13,<2.16\" numpy<2.0`.\n",
    "- Tăng `NUM_STEPS` và kích thước lô để có độ chính xác cao hơn (hãy chú ý đến bộ nhớ GPU).\n",
    "- Mở rộng `label_map.pbtxt` và chuyển đổi TFRecord khi bạn có nhiều lớp hơn.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ebad58b-4230-4809-8cae-3a63af0fe270",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
