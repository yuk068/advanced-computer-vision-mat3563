{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17e0e407-5c5d-4660-899c-9c31b856739d",
   "metadata": {},
   "source": [
    "## Faster R-CNN Workshop\n",
    "\n",
    "### Content:\n",
    "\n",
    "- Test this\n",
    "- Test that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e506523-3190-47a6-b541-fa597aaac646",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Version: 2.5.1\n",
      "------------------------------\n",
      "CUDA Available: True\n",
      "CUDA Version (PyTorch compiled with): 12.1\n",
      "GPU Count: 1\n",
      "\n",
      "--- GPU 0 ---\n",
      "Name: NVIDIA GeForce RTX 3060\n",
      "Compute Capability: 8.6\n",
      "Total Memory: 12.00 GB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(f\"PyTorch Version: {torch.__version__}\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "cuda_available = torch.cuda.is_available()\n",
    "print(f\"CUDA Available: {cuda_available}\")\n",
    "\n",
    "if cuda_available:\n",
    "    print(f\"CUDA Version (PyTorch compiled with): {torch.version.cuda}\")\n",
    "    \n",
    "    num_gpus = torch.cuda.device_count()\n",
    "    print(f\"GPU Count: {num_gpus}\")\n",
    "    \n",
    "    for i in range(num_gpus):\n",
    "        props = torch.cuda.get_device_properties(i)\n",
    "        \n",
    "        total_memory_gb = props.total_memory / (1024**3)\n",
    "        \n",
    "        print(f\"\\n--- GPU {i} ---\")\n",
    "        print(f\"Name: {props.name}\")\n",
    "        print(f\"Compute Capability: {props.major}.{props.minor}\")\n",
    "        print(f\"Total Memory: {total_memory_gb:.2f} GB\")\n",
    "else:\n",
    "    print(\"\\nNo CUDA-enabled GPU detected.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21a1f0db-0b2e-47fc-8ba4-e7499b45682d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import json\n",
    "import warnings\n",
    "warnings.ig\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from torchvision.transforms import functional as F\n",
    "from torchvision import transforms as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a0ae08c-c7d3-40bb-a28b-b2846ad36330",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is using CUDA.\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"Is using CUDA.\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"CUDA unavailable. Using CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afbfa2d2-30ec-4f70-95c2-1cebcda485ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11 (acv_torch)",
   "language": "python",
   "name": "acv_torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
