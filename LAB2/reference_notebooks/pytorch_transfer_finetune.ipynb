{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7fc30599",
   "metadata": {},
   "source": [
    "# Image Classification: Transfer Learning & Fine-tuning with PyTorch\n",
    "\n",
    "Chương trình này tải hình ảnh từ một thư mục cục bộ (nhãn từ tên thư mục con), chia chúng thành các thư mục train/validation (nếu cần), huấn luyện một mô hình **pretrained**  (đã được huấn luyện trước) với tùy chọn **partial freezing**  (đóng băng một phần) các lớp, và báo cáo các số liệu (độ chính xác, độ chính xác, độ thu hồi, F1) cùng với một ma trận nhầm lẫn.\n",
    "\n",
    "**Định dạng thư mục** (hai tùy chọn):\n",
    "1. Thư mục gốc đơn với các thư mục con lớp (schương trình sẽ chia các class dựa vào tên thư mụa):\n",
    "```\n",
    "data_root/\n",
    "class_a/ img1.jpg ...\n",
    "class_b/ img2.jpg ...\n",
    "```\n",
    "2. Chia trước các thư mục `train/` và `val/` (chương trình sẽ đọc và sử dụng chúng (tên thư mục) trực tiếp để phân chia):\n",
    "```\n",
    "data_root/\n",
    "train/ class_a/..., class_b/...\n",
    "val/ class_a/..., class_b/...\n",
    "Gửi ý kiến phản hồi\n",
    "Bảng điều khiển bên\n",
    "Các bản dịch đã thực hiện\n",
    "Đã lưu\n",
    "   ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e097c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== Configuration (edit me) ===============================================\n",
    "from pathlib import Path\n",
    "\n",
    "# Path to your dataset root (change this!)\n",
    "DATA_ROOT = Path(\"data_root\")  # e.g., Path(r\"D:/datasets/flowers\")\n",
    "\n",
    "# If your DATA_ROOT already has 'train' and 'val' subfolders set this to False\n",
    "NEED_RANDOM_SPLIT = True\n",
    "\n",
    "# Proportions when NEED_RANDOM_SPLIT=True\n",
    "TRAIN_RATIO = 0.8  # 80% train, 20% val\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "# Choose a model: 'resnet18', 'resnet50', 'efficientnet_b0', 'mobilenet_v3_small'\n",
    "MODEL_NAME = \"resnet18\"\n",
    "\n",
    "# Image size (short side resize & center-crop/RandomResizedCrop)\n",
    "IMAGE_SIZE = 224\n",
    "\n",
    "# Batch size and epochs\n",
    "BATCH_SIZE = 32\n",
    "NUM_EPOCHS = 10\n",
    "\n",
    "# Learning rates\n",
    "LR_BACKBONE = 1e-4   # for frozen/unfrozen backbone (if frozen, optimizer ignores params)\n",
    "LR_CLASSIFIER = 1e-3 # usually higher for the new head\n",
    "\n",
    "# Freeze strategy:\n",
    "# 'all_frozen' -> freeze all backbone, train only new classifier\n",
    "# 'partial'    -> unfreeze last block(s) while earlier layers stay frozen\n",
    "# 'none'       -> unfreeze everything (full fine-tuning)\n",
    "FREEZE_STRATEGY = \"partial\"\n",
    "\n",
    "# Number of last blocks to unfreeze for 'partial' (best-effort per architecture)\n",
    "UNFREEZE_LAST_BLOCKS = 1\n",
    "\n",
    "# Mixed precision training (speeds up on modern GPUs)\n",
    "USE_AMP = True\n",
    "\n",
    "# Workers for data loading\n",
    "NUM_WORKERS = 2\n",
    "\n",
    "# Where to save best model\n",
    "OUTPUT_DIR = Path(\"./outputs\")\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "CHECKPOINT_PATH = OUTPUT_DIR / \"best_model.pt\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b7d813",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== Imports ================================================================\n",
    "import os, math, time, itertools, json, random\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, random_split, Subset\n",
    "from torchvision import datasets, transforms, models\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Try to import sklearn (used for metrics); fallback to manual if unavailable\n",
    "try:\n",
    "    from sklearn.metrics import confusion_matrix, classification_report\n",
    "    HAVE_SKLEARN = True\n",
    "except Exception:\n",
    "    HAVE_SKLEARN = False\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cbcb336",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== Data transforms ========================================================\n",
    "# Augmentations for train, lighter transforms for val\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(IMAGE_SIZE),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize(IMAGE_SIZE + 32),\n",
    "    transforms.CenterCrop(IMAGE_SIZE),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225]),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c707ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== Dataset & split logic ==================================================\n",
    "def build_datasets(data_root: Path, need_random_split=True, train_ratio=0.8, seed=42):\n",
    "    data_root = Path(data_root)\n",
    "    if not data_root.exists():\n",
    "        raise FileNotFoundError(f\"DATA_ROOT not found: {data_root.resolve()}\")\n",
    "    \n",
    "    has_train_val = (data_root / 'train').exists() and (data_root / 'val').exists()\n",
    "    \n",
    "    if has_train_val and not need_random_split:\n",
    "        train_ds = datasets.ImageFolder(data_root / 'train', transform=train_transform)\n",
    "        val_ds   = datasets.ImageFolder(data_root / 'val',   transform=val_transform)\n",
    "        return train_ds, val_ds\n",
    "    \n",
    "    # Single folder: split randomly\n",
    "    full_ds = datasets.ImageFolder(data_root, transform=None)  # transform later per split\n",
    "    n_total = len(full_ds.samples)\n",
    "    n_train = int(n_total * train_ratio)\n",
    "    n_val   = n_total - n_train\n",
    "    \n",
    "    # Deterministic split\n",
    "    g = torch.Generator().manual_seed(seed)\n",
    "    idx_train, idx_val = torch.utils.data.random_split(range(n_total), [n_train, n_val], generator=g)\n",
    "    \n",
    "    # Wrap as Subset with proper transforms\n",
    "    train_raw = Subset(datasets.ImageFolder(data_root, transform=train_transform), idx_train.indices)\n",
    "    val_raw   = Subset(datasets.ImageFolder(data_root, transform=val_transform),   idx_val.indices)\n",
    "    \n",
    "    # Need to ensure classes/targets are consistent with ImageFolder mapping\n",
    "    return train_raw, val_raw\n",
    "\n",
    "train_ds, val_ds = build_datasets(DATA_ROOT, NEED_RANDOM_SPLIT, TRAIN_RATIO, RANDOM_SEED)\n",
    "\n",
    "class_names = train_ds.dataset.classes if hasattr(train_ds, 'dataset') else train_ds.classes\n",
    "num_classes = len(class_names)\n",
    "print(\"Classes:\", class_names)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS, pin_memory=True)\n",
    "val_loader   = DataLoader(val_ds,   batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d30902c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== Model factory ==========================================================\n",
    "def build_model(name: str, num_classes: int):\n",
    "    name = name.lower()\n",
    "    if name == 'resnet18':\n",
    "        m = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)\n",
    "        in_feats = m.fc.in_features\n",
    "        m.fc = nn.Linear(in_feats, num_classes)\n",
    "        backbone = ['conv1', 'bn1', 'layer1', 'layer2', 'layer3', 'layer4']\n",
    "        head = ['fc']\n",
    "    elif name == 'resnet50':\n",
    "        m = models.resnet50(weights=models.ResNet50_Weights.DEFAULT)\n",
    "        in_feats = m.fc.in_features\n",
    "        m.fc = nn.Linear(in_feats, num_classes)\n",
    "        backbone = ['conv1', 'bn1', 'layer1', 'layer2', 'layer3', 'layer4']\n",
    "        head = ['fc']\n",
    "    elif name == 'efficientnet_b0':\n",
    "        m = models.efficientnet_b0(weights=models.EfficientNet_B0_Weights.DEFAULT)\n",
    "        in_feats = m.classifier[1].in_features\n",
    "        m.classifier[1] = nn.Linear(in_feats, num_classes)\n",
    "        backbone = ['features']\n",
    "        head = ['classifier']\n",
    "    elif name == 'mobilenet_v3_small':\n",
    "        m = models.mobilenet_v3_small(weights=models.MobileNet_V3_Small_Weights.DEFAULT)\n",
    "        in_feats = m.classifier[3].in_features\n",
    "        m.classifier[3] = nn.Linear(in_feats, num_classes)\n",
    "        backbone = ['features']\n",
    "        head = ['classifier']\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown MODEL_NAME: {name}\")\n",
    "    return m, backbone, head\n",
    "\n",
    "model, backbone_names, head_names = build_model(MODEL_NAME, num_classes)\n",
    "\n",
    "# Freeze strategy\n",
    "def set_freeze_strategy(model, backbone_names, head_names, strategy='partial', unfreeze_last_blocks=1):\n",
    "    # First: freeze everything\n",
    "    for p in model.parameters():\n",
    "        p.requires_grad = False\n",
    "    \n",
    "    if strategy == 'all_frozen':\n",
    "        # Unfreeze only head\n",
    "        for name in head_names:\n",
    "            for p in getattr(model, name).parameters():\n",
    "                p.requires_grad = True\n",
    "    elif strategy == 'partial':\n",
    "        # Unfreeze head\n",
    "        for name in head_names:\n",
    "            for p in getattr(model, name).parameters():\n",
    "                p.requires_grad = True\n",
    "        # Unfreeze last N blocks (best-effort per architecture)\n",
    "        # Works for resnet layer{1..4} and for features-based nets\n",
    "        if hasattr(model, 'layer4'):  # resnet\n",
    "            layers = [getattr(model, f'layer{i}') for i in range(1,5)]\n",
    "            for block in layers[-unfreeze_last_blocks:]:\n",
    "                for p in block.parameters():\n",
    "                    p.requires_grad = True\n",
    "        elif hasattr(model, 'features'):\n",
    "            # Unfreeze last N stages in features (e.g., EfficientNet/MobileNet)\n",
    "            total = len(model.features)\n",
    "            start = max(0, total - unfreeze_last_blocks)\n",
    "            for i in range(start, total):\n",
    "                for p in model.features[i].parameters():\n",
    "                    p.requires_grad = True\n",
    "    elif strategy == 'none':\n",
    "        # Unfreeze everything\n",
    "        for p in model.parameters():\n",
    "            p.requires_grad = True\n",
    "    else:\n",
    "        raise ValueError(\"FREEZE_STRATEGY must be one of {'all_frozen','partial','none'}\")\n",
    "\n",
    "set_freeze_strategy(model, backbone_names, head_names, FREEZE_STRATEGY, UNFREEZE_LAST_BLOCKS)\n",
    "model = model.to(device)\n",
    "\n",
    "# Count trainable parameters\n",
    "n_trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "n_total = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Trainable params: {n_trainable:,} / {n_total:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "861857fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== Optimizer, loss, scheduler ============================================\n",
    "# Set different LRs for backbone vs head when applicable\n",
    "def param_groups(model, backbone_names, head_names, lr_backbone, lr_classifier):\n",
    "    groups = []\n",
    "    backbone_params = []\n",
    "    head_params = []\n",
    "    for name, module in model.named_children():\n",
    "        if name in head_names:\n",
    "            head_params += [p for p in module.parameters() if p.requires_grad]\n",
    "        elif name in backbone_names:\n",
    "            backbone_params += [p for p in module.parameters() if p.requires_grad]\n",
    "        else:\n",
    "            # modules like 'avgpool' etc. -> treat as backbone\n",
    "            backbone_params += [p for p in module.parameters() if p.requires_grad]\n",
    "    if backbone_params:\n",
    "        groups.append({'params': backbone_params, 'lr': lr_backbone})\n",
    "    if head_params:\n",
    "        groups.append({'params': head_params, 'lr': lr_classifier})\n",
    "    return groups\n",
    "\n",
    "optimizer = optim.AdamW(param_groups(model, backbone_names, head_names, LR_BACKBONE, LR_CLASSIFIER), weight_decay=1e-4)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=max(1, NUM_EPOCHS-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17d29ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== Training & evaluation ==================================================\n",
    "scaler = torch.cuda.amp.GradScaler(enabled=USE_AMP)\n",
    "\n",
    "def train_one_epoch(model, loader, optimizer, scaler, device):\n",
    "    model.train()\n",
    "    running_loss, running_correct, n = 0.0, 0, 0\n",
    "    for images, targets in loader:\n",
    "        images = images.to(device, non_blocking=True)\n",
    "        targets = targets.to(device, non_blocking=True)\n",
    "\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        with torch.cuda.amp.autocast(enabled=USE_AMP):\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, targets)\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        preds = outputs.argmax(1)\n",
    "        running_loss += loss.item() * images.size(0)\n",
    "        running_correct += (preds == targets).sum().item()\n",
    "        n += images.size(0)\n",
    "    return running_loss / max(1, n), running_correct / max(1, n)\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model, loader, device):\n",
    "    model.eval()\n",
    "    all_preds, all_targets = [], []\n",
    "    running_loss, running_correct, n = 0.0, 0, 0\n",
    "    for images, targets in loader:\n",
    "        images = images.to(device, non_blocking=True)\n",
    "        targets = targets.to(device, non_blocking=True)\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, targets)\n",
    "        preds = outputs.argmax(1)\n",
    "        running_loss += loss.item() * images.size(0)\n",
    "        running_correct += (preds == targets).sum().item()\n",
    "        n += images.size(0)\n",
    "        all_preds.append(preds.cpu())\n",
    "        all_targets.append(targets.cpu())\n",
    "    all_preds = torch.cat(all_preds).numpy()\n",
    "    all_targets = torch.cat(all_targets).numpy()\n",
    "    avg_loss = running_loss / max(1, n)\n",
    "    acc = running_correct / max(1, n)\n",
    "    return avg_loss, acc, all_targets, all_preds\n",
    "\n",
    "history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': []}\n",
    "best_acc, best_state = -1.0, None\n",
    "\n",
    "for epoch in range(1, NUM_EPOCHS+1):\n",
    "    t0 = time.time()\n",
    "    tr_loss, tr_acc = train_one_epoch(model, train_loader, optimizer, scaler, device)\n",
    "    val_loss, val_acc, y_true, y_pred = evaluate(model, val_loader, device)\n",
    "    scheduler.step()\n",
    "    \n",
    "    history['train_loss'].append(tr_loss)\n",
    "    history['train_acc'].append(tr_acc)\n",
    "    history['val_loss'].append(val_loss)\n",
    "    history['val_acc'].append(val_acc)\n",
    "    \n",
    "    if val_acc > best_acc:\n",
    "        best_acc = val_acc\n",
    "        best_state = {k: v.cpu() for k, v in model.state_dict().items()}\n",
    "        torch.save({'model_state': best_state,\n",
    "                    'class_names': class_names,\n",
    "                    'model_name': MODEL_NAME}, str(CHECKPOINT_PATH))\n",
    "    \n",
    "    dt = time.time() - t0\n",
    "    print(f\"Epoch {epoch:03d}/{NUM_EPOCHS} | \"\n",
    "          f\"train_loss={tr_loss:.4f} acc={tr_acc:.4f} | \"\n",
    "          f\"val_loss={val_loss:.4f} acc={val_acc:.4f} | \"\n",
    "          f\"time={dt:.1f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b07b5a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== Plot training curves ===================================================\n",
    "plt.figure()\n",
    "plt.plot(history['train_loss'], label='train_loss')\n",
    "plt.plot(history['val_loss'], label='val_loss')\n",
    "plt.xlabel('epoch'); plt.ylabel('loss'); plt.title('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(history['train_acc'], label='train_acc')\n",
    "plt.plot(history['val_acc'], label='val_acc')\n",
    "plt.xlabel('epoch'); plt.ylabel('accuracy'); plt.title('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb69eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== Detailed metrics =======================================================\n",
    "if HAVE_SKLEARN:\n",
    "    print(\"\\nClassification report (sklearn):\\n\")\n",
    "    print(classification_report(y_true, y_pred, target_names=class_names, digits=4))\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=list(range(num_classes)))\n",
    "else:\n",
    "    print(\"\\nscikit-learn is not available. Computing basic metrics manually.\\n\")\n",
    "    # Confusion matrix (manual)\n",
    "    cm = np.zeros((num_classes, num_classes), dtype=int)\n",
    "    for t, p in zip(y_true, y_pred):\n",
    "        cm[t, p] += 1\n",
    "    # Per-class precision/recall/F1 (macro)\n",
    "    eps = 1e-12\n",
    "    precs, recs, f1s = [], [], []\n",
    "    for c in range(num_classes):\n",
    "        tp = cm[c, c]\n",
    "        fp = cm[:, c].sum() - tp\n",
    "        fn = cm[c, :].sum() - tp\n",
    "        precision = tp / max(1, tp + fp + eps)\n",
    "        recall    = tp / max(1, tp + fn + eps)\n",
    "        f1        = 2 * precision * recall / max(eps, precision + recall)\n",
    "        precs.append(precision); recs.append(recall); f1s.append(f1)\n",
    "    print(\"Per-class metrics:\")\n",
    "    for i, name in enumerate(class_names):\n",
    "        print(f\"{name:20s}  P={precs[i]:.4f}  R={recs[i]:.4f}  F1={f1s[i]:.4f}\")\n",
    "    print(f\"\\nMacro Precision={np.mean(precs):.4f}, Recall={np.mean(recs):.4f}, F1={np.mean(f1s):.4f}\")\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure()\n",
    "im = plt.imshow(cm, interpolation='nearest')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.colorbar(im, fraction=0.046, pad=0.04)\n",
    "tick_marks = np.arange(num_classes)\n",
    "plt.xticks(tick_marks, class_names, rotation=45, ha='right')\n",
    "plt.yticks(tick_marks, class_names)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e3a551",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== Inference utility ======================================================\n",
    "from PIL import Image\n",
    "\n",
    "def load_checkpoint(path, device=device):\n",
    "    ckpt = torch.load(path, map_location=device)\n",
    "    m, _, _ = build_model(ckpt['model_name'], num_classes=len(ckpt['class_names']))\n",
    "    m.load_state_dict({k: v for k, v in ckpt['model_state'].items()})\n",
    "    m.eval().to(device)\n",
    "    return m, ckpt['class_names']\n",
    "\n",
    "def predict_image(img_path, model, class_names, image_size=IMAGE_SIZE):\n",
    "    tfm = transforms.Compose([\n",
    "        transforms.Resize(image_size + 32),\n",
    "        transforms.CenterCrop(image_size),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                             std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "    img = Image.open(img_path).convert('RGB')\n",
    "    x = tfm(img).unsqueeze(0).to(device)\n",
    "    with torch.no_grad():\n",
    "        logits = model(x)\n",
    "        probs = torch.softmax(logits, dim=1).cpu().numpy()[0]\n",
    "    idx = int(np.argmax(probs))\n",
    "    return class_names[idx], float(probs[idx])\n",
    "\n",
    "print(\"\\nUsage example (after training):\\n\"\n",
    "      \"model, classes = load_checkpoint(CHECKPOINT_PATH)\\n\"\n",
    "      \"label, conf = predict_image('path/to/image.jpg', model, classes)\\n\"\n",
    "      \"print(label, conf)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
